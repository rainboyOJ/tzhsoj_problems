## 描述

样例: n 皇后问题 [经典问题] 将 n 个皇后摆放在一个 n x n 的棋盘上，使得每一个皇后都无法攻击到其他皇后。 深度优先搜索 (DFS) 显而易见，最直接的方法就是把皇后一个一个地摆放在棋盘上的合法位置上，枚举所有可能寻找可行解。可以发现在棋盘上的每一行（或列）都存在且仅存在一个皇后，所以，在递归的每一步中，只需要在当前行(或列）中寻找合法格，选择其中一个格摆放一个皇后。 1 search(col) 2 if filled all columns 3 print solution and exit 4 for each row 5 if board(row, col) is not attacked 6 place queen at (row, col) 7 search(col+1) 8 remove queen at (row, col) 从search(0)开始搜索，由于在每一步中可选择的节点较少，该方法可以较快地求解：当一定数量的皇后被摆放在棋盘上后那些不会被攻击到的节点的数量将迅速减少。 这是深度优先搜索的一个经典例题，该算法总是能尽可能快地抵达搜索树的底层：当 k 个皇后被摆放到棋盘上时，可以马上确定如何在棋盘上摆放下一个皇后，而不需要去考虑其他的顺序摆放皇后可能造成的影响（如当前情况是否为最优情况），该方法有时可以在找到可行解之前避免复杂的计算，这是十分值得的。 深度优先搜索具有一些特性，考虑下图的搜索树： <img border=0 src=http://60.191.162.158:8080/JudgeOnline/images/p1023rec1.gif> 该算法用逐步加层的方法搜索并且适当时回溯，在每一个已被访问过的节点上标号，以便下次回溯时不会再次被搜索。绘画般地，搜索树将以如下顺序被遍历： <img border=0 src=http://60.191.162.158:8080/JudgeOnline/images/p1023rec2.gif> 复杂度： 假设搜索树有 d 层（在样例中 d=n ，即棋盘的列数）。再假设每一个节点都有 c 个子节点（在样例中，同样 c=n ，即棋盘的行数，但最后一层没有子节点，除外）。那么整个搜索花去的时间将与 cd 成正比，是指数级的。但是其需要的空间较小，除了搜索树以外，仅需要用一个栈存储当前路径所经过的节点，其空间复杂度为 O(d) 。 样例：骑士覆盖问题[经典问题] 在一个 n x n 的棋盘中摆放尽量少的骑士，使得棋盘的每一格都会被至少一个骑士攻击到。但骑士无法攻击到它自己站的位置. 广度优先搜索 (BFS) 在这里，最好的方法莫过于先确定 k 个骑士能否实现后再尝试 k+1 个骑士，这就叫广度优先搜索。通常，广度优先搜索需用队列来帮助实现。 1 process(state) 2 for each possible next state from this one 3 enqueue next state 4 search() 5 enqueue initial state 6 while !empty(queue) 7 state = get state from queue 8 process(state) 广度优先搜索得名于它的实现方式：每次都先将搜索树某一层的所有节点全部访问完毕后再访问下一层, 再利用先前的那颗搜索树，广度优先搜索以如下顺序遍历： <img border=0 src=http://60.191.162.158:8080/JudgeOnline/images/p1023rec3.gif> 首先访问根节点，而后是搜索树第一层的所有节点，之后第二层、第三层……以此类推。 复杂度： 广度优先搜索所需的空间与深度优先搜索所需的不同（ n 皇后问题的空间复杂度为 O(n) ）,广度优先搜索的空间复杂取决于每层的节点数。如果搜索树有 k 层，每个节点有 c 个子节点，那么最后将可能有 c k 个数据被存入队列，这个复杂度无疑是巨大的。所以在使用广度优先搜索时，应小心处理空间问题。 迭代加深搜索 (ID) 广度优先搜索可以用迭代加深搜索代替。迭代加深搜索实质是限定下界的深度优先搜索，即首先允许深度优先搜索搜索 k 层搜索树，若没有发现可行解，再将 k+1 后再进行一次以上步骤，直到搜索到可行解。这个“模仿广度优先搜索”搜索法比起广搜是牺牲了时间，但节约了空间。 1 truncated_dfsearch(hnextpos, depth) 2 if board is covered 3 print solution and exit 4 if depth == 0 5 return 6 for i from nextpos to n*n 7 put knight at i 8 truncated_dfsearch(i+1, depth-1) 9 remove knight at i 10 dfid_search 11 for depth = 0 to max_depth 12 truncated_dfsearch(0, depth) 复杂度： 　 ID时间复杂度与DFS的时间复杂度（O(n)）不同，另一方面，它要更复杂，某次DFS若限界 k 层，则耗时 ck 。若搜索树共有 d 层，则一个完整的DFS-ID将耗时 c0 + c1 + c2 + ... + cd 。如果 c = 2 ，那么式子的和是 cd+1 - 1 ，大约是同效BFS的两倍。当 c > 2 时（子节点的数目大于2），差距将变小：ID的时间消耗不可能大于同效BFS的两倍。 所以，但数据较大时，ID-DFS并不比BFS慢，但是空间复杂度却与DFS相同，比BFS小得多。 算法选择： 当你已经知道某题是一道搜索题，那么选择正确的搜索方式是十分重要的。下面给你一些选择的依据。 简表： 搜索方式 时间 空间 使用情况 DFS O(c k) O(k) 必须遍历整棵树，要求出解的深度或经的过节点，或者你并不需要解的深度最小。 BFS O(c d ) O(c d ) 了解到解十分靠近根节点，或者你需要解的深度最小。 DFS+ID O(c d) O(d) 需要做BFS，但没有足够的空间，时间却很充裕。 d ：解的深度 k ：搜索树的深度 d <= k 记住每一种搜索法的优势。如果要求求出最接近根节点的解，则使用BFD或ID。而如果是其他的情况，DFS是一种很好的搜索方式。如果没有足够的时间搜出所有解。那么使用的方法应最容易搜出可行解，如果答案可能离根节点较近，那么就应该用BFS或ID，相反，如果答案离根节点较远，那么使用DFS较好。还有，请仔细小心空间的限制。如果空间不足以让你使用BFS，那么请使用迭代加深吧！ 类似问题： 超级质数肋骨[USACO 1994 决赛] 一个数，如果它从右到左的一位、两位直到N位（N是）所构成的数都是质数，那么它就称为超级质数。例如：233、23、2都是质数，所以233是超级质数。要求：读入一个数N（N <= 9），编程输出所有有N位的超级质数。 这题应使用DFS，因为每一个答案都有N层（最底层），所以DFS是最好的． Betsy的旅行 [USACO 1995 资格赛] 一个正方形的小镇被分成 NxN (2 <= N <= 6）个小方格，Besty 要从左上角的方格到达左下角的方格，并且经过每一次方格都恰好经过一次。编程对于给定的 N 计算出 Besty 能采用的所有的旅行路线的数目。 这题要求求出解的数量，所以整颗搜索树都必须被遍历，这就与可行解的位置与出解速度没有关系了。所以这题可以使用BFS或DFS，又因为DFS需要的空间较少，所以DFS是较好的． 奶牛运输 [USACO 1995 决赛] 奶牛运输公司拥有一辆运输卡车与牧场 A ，运输公司的任务是在A，B，C，D，E，F和G七个农场之间运输奶牛。每两个农场之间的路程（可以用floyed改变）已给出。每天早晨，运输公司都必须确定一条运输路线，使得运输的总距离最短。但必须遵守以下规则： 农场 A 是公司的基地。每天的运输都必须从这开始并且在这结束。 卡车任何时刻都只能最多承载一头奶牛。 给出的数据是奶牛的原先位置与运输结束后奶牛所在的位置。 而你的任务是在上述规则内寻找最短的运输路线。 在发现最优解时必须比较所有可行解，所以必须遍历整棵搜索树。所以，可以用DFS解题． 横越沙漠 [1992 IOI] 一群沙漠探险者正尝试着让他们中的一部分人横渡沙漠。每一个探险者可以携带一定数量的水，同时他们每天也要喝掉一定量的水。已知每个探险者可携带的水量与每天需要的水量都不同。给出每个探险者能携带的水量与需要的水量与横渡沙漠所需的天数，请编程求出最多能有几个人能横渡沙漠。所有探险者都必须存活，所以有些探险者在中途必须返回，返回时也必须携带足够的水。当然，如果一个探险者返回时有剩余的水（除去返回所需的水以外），他可以把剩余的水送给他的一个同伴，如果它的同伴可以携带的话。 这题可以分成两个小问题，一个是如何为探险者分组，另一个是某些探险者应在何处返回。所以使用ID-DFS是可行的。首先尝试每一个探险者能否独自横渡，然后是两个人配合，三个人配合。直到结束。 

## 输入格式

Crafting Winning Solutions A good way to get a competitive edge is to write down a game plan for what you're going to do in a contest round. This will help you script out your actions, in terms of what to do both when things go right and when things go wrong. This way you can spend your thinking time in the round figuring out programming problems and not trying to figure out what the heck you should do next... it's sort of like precomputing your reactions to most situations. Mental preparation is also important. Game Plan For A Contest Round Read through ALL the problems FIRST; sketch notes with algorithm, complexity, the numbers, data structs, tricky details, ... Brainstorm many possible algorithms - then pick the stupidest that works! DO THE MATH! (space & time complexity, and plug in actual expected and worst case numbers) Try to break the algorithm - use special (degenerate?) test cases Order the problems: shortest job first, in terms of your effort (shortest to longest: done it before, easy, unfamiliar, hard) Coding a problem - For each, one at a time: Finalize algorithm Create test data for tricky cases Write data structures Code the input routine and test it (write extra output routines to show data?) Code the output routine and test it Stepwise refinement: write comments outlining the program logic Fill in code and debug one section at a time Get it working & verify correctness (use trivial test cases) Try to break the code - use special cases for code correctness Optimize progressively - only as much as needed, and keep all versions (use hard test cases to figure out actual runtime) Time management strategy and "damage control" scenarios Have a plan for what to do when various (foreseeable!) things go wrong; imagine problems you might have and figure out how you want to react. The central question is: "When do you spend more time debugging a program, and when do you cut your losses and move on?". Consider these issues: How long have you spent debugging it already? What type of bug do you seem to have? Is your algorithm wrong? Do you data structures need to be changed? Do you have any clue about what's going wrong? A short amount (20 mins) of debugging is better than switching to anything else; but you might be able to solve another from scratch in 45 mins. When do you go back to a problem you've abandoned previously? When do you spend more time optimizing a program, and when do you switch? Consider from here out - forget prior effort, focus on the future: how can you get the most points in the next hour with what you have? Have a checklist to use before turning in your solutions: Code freeze five minutes before end of contest? Turn asserts off. Turn off debugging output. Tips & Tricks Brute force it when you can KISS: Simple is smart! Hint: focus on limits (specified in problem statement) Waste memory when it makes your life easier (if you can get away with it) Don't delete your extra debugging output, comment it out Optimize progressively, and only as much as needed Keep all working versions! Code to debug: whitespace is good, use meaningful variable names, don't reuse variables, stepwise refinement, COMMENT BEFORE CODE. Avoid pointers if you can Avoid dynamic memory like the plague: statically allocate everything. Try not to use floating point; if you have to, put tolerances in everywhere (never test equality) Comments on comments: Not long prose, just brief notes Explain high-level functionality: ++i; /* increase the value of i by */ is worse than useless Explain code trickery Delimit & document functional sections As if to someone intelligent who knows the problem, but not the code Anything you had to think about Anything you looked at even once saying, "now what does that do again?" Always comment order of array indices Keep a log of your performance in each contest: successes, mistakes, and what you could have done better; use this to rewrite and improve your game plan! Complexity Basics and order notation The fundamental basis of complexity analysis revolves around the notion of ``big oh'' notation, for instance: O(N). This means that the algorithm's execution speed or memory usage will double when the problem size doubles. An algorithm of O(N 2) will run about four times slower (or use 4x more space) when the problem size doubles. Constant-time or space algorithms are denoted O(1). This concept applies to time and space both; here we will concentrate discussion on time. One deduces the O() run time of a program by examining its loops. The most nested (and hence slowest) loop dominates the run time and is the only one mentioned when discussing O() notation. A program with a single loop and a nested loop (presumably loops that execute N times each) is O(N 2), even though there is also a O(N) loop present. Of course, recursion also counts as a loop and recursive programs can have orders like O(b N), O(N!), or even O(N N). Rules of thumb When analyzing an algorithm to figure out how long it might run for a given dataset, the first rule of thumb is: modern (2004) computers can deal with 100M actions per second. In a five second time limit program, about 500M actions can be handled. Really well optimized programs might be able to double or even quadruple that number. Challenging algorithms might only be able to handle half that much. Current contests usually have a time limit of 1 second for large datasets. 16MB maximum memory use 210 ~approx~ 10 3 If you have k nested loops running about N iterations each, the program has O(N k) complexity. If your program is recursive with b recursive calls per level and has l levels, the program O(b l) complexity. Bear in mind that there are N! permutations and 2 n subsets or combinations of N elements when dealing with those kinds of algorithms. The best times for sorting N elements are O(N log N). DO THE MATH! Plug in the numbers. Examples A single loop with N iterations is O(N): 1 sum = 0 2 for i = 1 to n 3 sum = sum + i A double nested loop is often O(N 2): # fill array a with N elements 1 for i = 1 to n-1 2 for j = i + 1 to n 3 if (a[i] > a[j]) swap (a[i], a[j]) Note that even though this loop executes N x (N+1) / 2 iterations of the if statement, it is O(N 2) since doubling N quadruples the execution times. Consider this well balanced binary tree with four levels: An algorithm that traverses a general binary tree will have complexity O(2 N). Solution Paradigms Generating vs. Filtering Programs that generate lots of possible answers and then choose the ones that are correct (imagine an 8-queen solver) are filters. Those that hone in exactly on the correct answer without any false starts are generators. Generally, filters are easier (faster) to code and run slower. Do the math to see if a filter is good enough or if you need to try and create a generator. Precomputation Sometimes it is helpful to generate tables or other data structures that enable the fastest possible lookup of a result. This is called precomputation (in which one trades space for time). One might either compile precomputed data into a program, calculate it when the program starts, or just remember results as you compute them. A program that must translate letters from upper to lower case when they are in upper case can do a very fast table lookup that requires no conditionals, for example. Contest problems often use prime numbers - many times it is practical to generate a long list of primes for use elsewhere in a program. Decomposition (The Hardest Thing At Programming Contests) While there are fewer than 20 basic algorithms used in contest problems, the challenge of combination problems that require a combination of two algorithms for solution is daunting. Try to separate the cues from different parts of the problem so that you can combine one algorithm with a loop or with another algorithm to solve different parts of the problem independently. Note that sometimes you can use the same algorithm twice on different (independent!) parts of your data to significantly improve your running time. Symmetries Many problems have symmetries (e.g., distance between a pair of points is often the same either way you traverse the points). Symmetries can be 2-way, 4-way, 8-way, and more. Try to exploit symmetries to reduce execution time. For instance, with 4-way symmetry, you solve only one fourth of the problem and then write down the four solutions that share symmetry with the single answer (look out for self-symmetric solutions which should only be output once or twice, of course). Forward vs. Backward Surprisingly, many contest problems work far better when solved backwards than when using a frontal attack. Be on the lookout for processing data in reverse order or building an attack that looks at the data in some order or fashion other than the obvious. Simplification Some problems can be rephrased into a somewhat different problem such that if you solve the new problem, you either already have or can easily find the solution to the original one; of course, you should solve the easier of the two only. Alternatively, like induction, for some problems one can make a small change to the solution of a slightly smaller problem to find the full answer. 

## 输出格式

 

## 输入样例

```plaintext
 
```

## 输出样例

```plaintext
 
```



 



 

